
# Stages to run
stages:
    - name: PZRailTrain
      threads_per_process: 2
    - name: PZRailEstimate
    - name: TXDaskLensSelector
      nprocess: 2

modules: txpipe

python_paths:
    - submodules/RAIL

# Where to put outputs
output_dir: data/dask/outputs

# How to run the pipeline: mini, parsl, or cwl
launcher:
    name: mini
    interval: 1.0

# Where to run the pipeline: cori-interactive, cori-batch, or local
site:
    name: local
    max_threads: 2

# python modules to import to search for stages
modules: txpipe

# configuration settings
config: examples/config/laptop_config.yml

# On NERSC, set this before running:
# export DATA=${LSST}/groups/WL/users/zuntz/data/metacal-testbed

inputs:
    # See README for paths to download these files
    shear_catalog: data/example/inputs/shear_catalog.hdf5
    photometry_catalog: data/example/inputs/photometry_catalog.hdf5
    photoz_training: submodules/RAIL/tests/data/test_dc2_training_9816.hdf5
    photoz_testing: submodules/RAIL/tests/data/test_dc2_validation_9816.hdf5
    calibration_table: data/example/inputs/sample_cosmodc2_w10year_errors.dat
    exposures: data/example/inputs/exposures.hdf5
    star_catalog: data/example/inputs/star_catalog.hdf5
    # This file comes with the code
    fiducial_cosmology: data/fiducial_cosmology.yml

# if supported by the launcher, restart the pipeline where it left off
# if interrupted
resume: True
# where to put output logs for individual stages
log_dir: data/dask/logs
# where to put an overall parsl pipeline log
pipeline_log: data/dask/log.txt
